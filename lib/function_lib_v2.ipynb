{"cells":[{"cell_type":"markdown","metadata":{"id":"Ycha_G9vBPYc"},"source":["#Step 2: DATA UNDERSTANDING"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import import_ipynb\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7J39LBRp32T9"},"outputs":[],"source":["# create statistics function\n","def continous_feature_describe(lst_cols, df):\n","    col_ = []\n","    count_ = []\n","    min_ = []\n","    max_ = []\n","    mean_ = []\n","    std_ = []\n","    var_ = []\n","    skewness_ = []\n","    kurtosis_ = []\n","    do_lech = []\n","    do_nhon = []\n","\n","    for i in lst_cols:\n","        col_.append(i)\n","        count_.append(df[i].count())\n","        min_.append(df[i].min())\n","        max_.append(df[i].max())\n","        mean_.append(df[i].mean())\n","        std_.append(df[i].std())\n","        var_.append(df[i].var())\n","        skewness_.append(df[i].skew())\n","        kurtosis_.append(df[i].kurtosis())\n","        \n","        if df[i].skew() > 0: do_lech.append('lech phai')\n","        elif df[i].skew() < 0: do_lech.append('lech trai')\n","        else: do_lech.append('doi xung')\n","            \n","        if df[i].kurtosis() > 0: do_nhon.append('nhon hon PP chuan')\n","        elif df[i].kurtosis() < 0: do_nhon.append('bet hon PP chuan')\n","        else: do_nhon.append('tuong duong PP chuan')\n","\n","    df_describe = pd.DataFrame({'feature_name': col_,\n","                               'count': count_,\n","                               'min': min_,\n","                               'max': max_,\n","                               'mean': mean_,\n","                               'std': std_,\n","                               'var': var_,\n","                                'skewness': skewness_,\n","                                'kurtosis': kurtosis_,\n","                                'do_lech': do_lech,\n","                                'do_nhon': do_nhon\n","                               })\n","    return df_describe"]},{"cell_type":"markdown","metadata":{"id":"iKXe4OLIBsVe"},"source":["#Step 4&5: MODELING & EVALUATION/ANALYZE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzZD9xCABq3T"},"outputs":[],"source":["# create Cross validation:\n","def Average_RMSE_Model(model, X, y, size=0.3, cv=10):\n","    import time\n","    from sklearn.model_selection import train_test_split    \n","    train_rmse=[]\n","    train_score=[]\n","    test_rmse=[]\n","    test_score=[]\n","    \n","    duration=[]\n","    for n in range(1, cv+1):                \n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size)                                             \n","        \n","        start=time.time()        \n","        model.fit(X_train, y_train)\n","        end=time.time()\n","        \n","        train_rmse.append(mean_squared_error(y_true=y_train, y_pred=model.predict(X_train), squared=False))\n","        test_rmse.append(mean_squared_error(y_true=y_test, y_pred=model.predict(X_test), squared=False))\n","        train_score.append(model.score(X_train, y_train))\n","        test_score.append(model.score(X_test, y_test))\n","\n","        duration.append((end-start)*1000)\n","        \n","    return np.mean(train_rmse), np.mean(train_score), np.mean(test_rmse), np.mean(test_score), np.mean(duration) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J70bGn3s4SlK"},"outputs":[],"source":["def Save_Object(obj, filename):\n","    with open(filename, 'wb') as file:\n","        pickle.dump(obj, file)\n","    return\n","def Load_Object(filename):\n","    with open(filename, 'rb') as file:\n","        obj = pickle.load(file)\n","    return obj"]},{"cell_type":"markdown","metadata":{"id":"rL0xpd0whQTp"},"source":["## Problem 1"]},{"cell_type":"markdown","metadata":{"id":"5xSjeykx1Q8n"},"source":["### Create def"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tWq9YRLst2N4"},"outputs":[],"source":["def data_cleaning(data):\n","    df = data.copy()\n","    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n","    # drop duplicates\n","    df = df.drop_duplicates() \n","    # change datatype\n","    df['Date'] = pd.to_datetime(df['Date']) \n","    # change column names\n","    df.columns = df.columns.str.replace(\" \",\"_\")\n","    df.columns = ['Date', 'AveragePrice', 'Total_Volume', 'PLU_4046','PLU_4225','PLU_4770',\n","          'Total_Bags', 'Small_Bags', 'Large_Bags', 'XLarge_Bags', 'type', 'year',\n","          'region']\n","    # remove some region: \n","    df = df.loc[df['region'] != \"TotalUS\",:]\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"FVTwGtjv3F3U"},"source":["### Create fit_transform function"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNXx4RdF/e+2ZKl39mr4clJ","collapsed_sections":[],"name":"function_lib.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"vscode":{"interpreter":{"hash":"5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"}}},"nbformat":4,"nbformat_minor":0}
